## What is AGS?
This field looks at the intersection of Artificial intelligence, neuroscience and philosophy<br>
Here some the questions it tries to answer
 - What is the nature of consciousness?
 - What is intelligence ?

### What is intelligence ?
There is'nt an agreed upon defintion of what intelligence,multiple viewpoints have been  put forward as to what intelligence which are summuarised in the page below [[1]](https://arxiv.org/abs/0706.3639)<br>
![Multiple Defintions from different POV](/images/intelligence_definitions.png)

Traditionally, machine learning (ML) is a subset of AI, while AI is a subset of AGI (or, depending on who’s asking, it is a way to achieve AGI). AGI is the broadest class containing both AI and ML, and traditional or colloquial AI is generally referred to as “narrow AI” or “weak AI”: the development of systems that dealt intelligently with a single, narrow domain <br>

The problem is that machines now are really good at narrow tasks, as in AI has excelled in specific domains like playing Go, spam detection, and Spotify playlist recommendations etc . However, computers now lack the ability to generalize knowledge to other domains. This is the heart of the issue,where the goal is attain 
"general intelligence" <br>

### What is General Intelligence ?[2]
Qualitatively speaking, though,there is broad agreement in the AGI community on some key features of general intelligence:
• General intelligence involves the ability to achieve a variety of goals, and carry out a variety
of tasks, in a variety of different contexts and environments.<br>
• A generally intelligent system should be able to handle problems and situations quite different
from those anticipated by its creators.<br>
• A generally intelligent system should be good at generalizing the knowledge it’s gained, so
as to transfer this knowledge from one problem or context to others.<br>
• Arbitrarily general intelligence is not possible given realistic resource constraints.<br>
• Real-world systems may display varying degrees of limited generality, but are inevitably
going to be a lot more efficient at learning some sorts of things than others; and for any
given real-world system, there will be some learning tasks on which it is unacceptably slow.
So real-world general intelligences are inevitably somewhat biased toward certain sorts of
goals and environments.<br>
• Humans display a higher level of general intelligence than existing AI programs do, and
apparently also a higher level than other animals.<br>
• It seems quite unlikely that humans happen to manifest a maximal level of general intelli-
gence, even relative to the goals and environment for which they have been evolutionarily
adapted.<br>

### Core AGI hypothesis
Another point broadly shared in the AGI community is confidence in what is called the “core AGI hypothesis,”<br>
The creation and study of synthetic intelligences with sufficiently broad
(e.g. human-level) scope and strong generalization capability, is at bottom qualitatively different
from the creation and study of synthetic intelligences with significantly narrower scope and weaker
generalization capability.


### References
1. Legg, Shane, and Marcus Hutter. “A collection of definitions of intelligence.” Frontiers in Artificial Intelligence and applications157 (2007): 17
2. Goertzel, Ben. “Artificial general intelligence: concept, state of the art, and future prospects.” Journal of Artificial General Intelligence 5.1 (2014): 1–48.
